# -*- coding: utf-8 -*-
"""
Created on Tue Sep  7 17:08:59 2021

@author: Gloria
"""
import pyblp
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy as sp
from scipy import stats
from openpyxl import load_workbook

pyblp.options.digits = 4 #this is set at 2 in the tutorial
pyblp.options.verbose = False
pyblp.__version__


###############################################################################
# CF2 
###############################################################################


#CF2 - off 0-10
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi1 = vfi[(vfi['supply_instruments2'] <10)]
product_data = vfi1.loc[(vfi1.block == "off"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<10] = 10 


cd "C:\Users\glori\Documents\Papers_202005\1_Paper\Replication\Python\Ramp\CF1\0-10\off_cf11"
import pickle
with open("off_cf11.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.147939581126052], #stats7 estimated value
    sigma=[23.0534945184412],
    gamma=[0.57656260377973, 1.83535403702242, 0.0807493433961324],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results

#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\0-10\off_cf21"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("off_cf21.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("off_cf21.txt", "rb") as myFile:
    ofF_cf21 = pickle.load(myFile)

#pvalues
a = off_cf21
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

off_cf21= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats16.xlsx') as writer:
    off_cf21.to_excel(writer, sheet_name = 'off_cf21', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) 
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\off_cf21\stats16.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\off_cf21\stats16.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)


#p1  10 
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi1 = vfi[(vfi['supply_instruments2'] <10)]
product_data = vfi1.loc[(vfi1.block == "peak1"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<10] = 10 

cd "C:\...\Replication\Python\Ramp\CF1\0-10\p1_cf11"
import pickle
with open("p1_cf11.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.150331073661664], #stats8 estimated value
    sigma=[6.47361600493637],
    gamma=[0.708567189779487, 2.24370496110694, -0.0249232367441543],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\0-10\p1_cf21"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p1_cf21.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p1_cf21.txt", "rb") as myFile:
    p1_cf21 = pickle.load(myFile)

#pvalues
a = p1_cf21
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p1_cf21= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats17.xlsx') as writer:
    p1_cf21.to_excel(writer, sheet_name = 'p1_cf21', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) #esto estaba vacio
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\p1_cf21\stats17.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\p1_cf21\stats17.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)

#p2  10 
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi1 = vfi[(vfi['supply_instruments2'] <10)]
product_data = vfi1.loc[(vfi1.block == "peak2"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<10] = 10 

cd "C:\...\Replication\Python\Ramp\CF1\0-10\p2_cf11"
import pickle
with open("p2_cf11.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.15062578549124], #stats9 estimated value
    sigma=[5.69515555173337],
    gamma=[0.743685703230258, 2.1589648627063, -0.0567839855257337],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\0-10\p2_cf21"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p2_cf21.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p2_cf21.txt", "rb") as myFile:
    p2_cf21 = pickle.load(myFile)

#pvalues
a = p2_cf21
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p2_cf21= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats18.xlsx') as writer:
    p2_cf21.to_excel(writer, sheet_name = 'p2_cf21', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) #esto estaba vacio
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\2_cf21\stats18.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\0-10\p2_cf21\stats18.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)



#off 20
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi2 = vfi[(vfi['supply_instruments2'] >=10) & (vfi['supply_instruments2'] <20)]
product_data = vfi2.loc[(vfi2.block == "off"), ]
product_data = product_data.drop(columns=["nesting_ids"])


del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<20] = 20 


cd "C:\...\Replication\Python\Ramp\CF1\10-20\off_cf12"
import pickle
with open("off_cf12.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.119737546904035], #stats10 estimated value
    sigma=[0.00779803442996207],
    gamma=[0.416464286231474, 1.73119128840037, -0.0310422686973118],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\10-20\off_cf22"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("off_cf22.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("off_cf22.txt", "rb") as myFile:
    ofF_cf22 = pickle.load(myFile)

#pvalues
a = off_cf22
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

off_cf22= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats19.xlsx') as writer:
    off_cf22.to_excel(writer, sheet_name = 'off_cf22', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) #esto estaba vacio
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\off_cf22\stats19.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\off_cf22\stats19.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)


#p1  20 
###############################################################################
cd "C:\...\1_Paper\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi2 = vfi[(vfi['supply_instruments2'] >=10) & (vfi['supply_instruments2'] <20)]
product_data = vfi2.loc[(vfi.block == "peak1"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<20] = 20 

cd "C:\...\Replication\Python\Ramp\CF1\10-20\p1_cf12"
import pickle
with open("p1_cf12.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.108483071436162], #stats11 estimated value
    sigma=[0.00628592724582569],
    gamma=[0.506897196649883, 1.85824123957891, -0.0248926252828916],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\10-20\p1_cf22"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p1_cf22.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p1_cf22.txt", "rb") as myFile:
    p1_cf22 = pickle.load(myFile)

#pvalues
a = p1_cf22
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p1_cf22= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats20.xlsx') as writer:
    p1_cf22.to_excel(writer, sheet_name = 'p1_cf22', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) 
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\p1_cf22\stats20.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\p1_cf22\stats20.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)

#p2  20 
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi2 = vfi[(vfi['supply_instruments2'] >=10) & (vfi['supply_instruments2'] <20)]
product_data = vfi2.loc[(vfi2.block == "peak2"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<20] = 20 

cd "C:\...\Replication\Python\Ramp\CF1\10-20\p2_cf12"
import pickle
with open("p2_cf12.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.118128485578066], #stats12 estimated value
    sigma=[0.00897005083941295],
    gamma=[0.475450633688175, 1.85494706280329, -0.0763778745462402],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\10-20\p2_cf22"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p2_cf22.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p2_cf22.txt", "rb") as myFile:
    p2_cf22 = pickle.load(myFile)

#pvalues
a = p2_cf22
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p2_cf22= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats21.xlsx') as writer:
    p2_cf22.to_excel(writer, sheet_name = 'p2_cf22', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) #esto estaba vacio
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\p2_cf22\stats21.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\10-20\p2_cf22\stats21.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)


#off 25
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi3 = vfi[(vfi['supply_instruments2'] <=20)]
product_data = vfi3.loc[(vfi3.block == "off"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<25] = 25 


cd "C:\...\Replication\Python\Ramp\CF1\20-\off_cf13"
import pickle
with open("off_cf13.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.16485264410972], #stats13 estimated value
    sigma=[435.254374217989],
    gamma=[0.607263586141864, 1.577669627818, 0.0585003809019735],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\20-\off_cf23"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("off_cf23.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("off_cf23.txt", "rb") as myFile:
    ofF_cf23 = pickle.load(myFile)

#pvalues
a = off_cf23
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

off_cf23= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats22.xlsx') as writer:
    off_cf23.to_excel(writer, sheet_name = 'off_cf23', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) 
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\off_cf23\stats22.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\off_cf23\stats22.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)

#p1  25 
###############################################################################
cd "C:\...r\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi3 = vfi[(vfi['supply_instruments2'] <=20)]
product_data = vfi3.loc[(vfi3.block == "peak1"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<25] = 25 

cd "C:\...\Replication\Python\Ramp\CF1\20-\p1_cf13"
import pickle
with open("p1_cf13.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.140989256916268], #stats14 estimated value
    sigma=[7.4257716515833],
    gamma=[0.680577397963908, 1.94286936339206, 0.0368047056917904],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\20-\p1_cf23"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p1_cf23.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p1_cf23.txt", "rb") as myFile:
    p1_cf23 = pickle.load(myFile)

#pvalues
a = p1_cf23
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p1_cf23= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats23.xlsx') as writer:
    p1_cf23.to_excel(writer, sheet_name = 'p1_cf23', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) 
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, pcf2, shcf2, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\p1_cf23\stats23.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\p1_cf23\stats23.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)

#p2  25
###############################################################################
cd "C:\...\Replication\R_paneldata\BLP"	

vfi = pd.read_csv(r'i1rv.cvs', index_col=False)
vfi3 = vfi[(vfi['supply_instruments2'] <=20)]
product_data = vfi3.loc[(vfi3.block == "peak2"), ]
product_data = product_data.drop(columns=["nesting_ids"])

del product_data['Unnamed: 0']

product_data['supply_instruments2'].values[product_data['supply_instruments2']<25] = 25 

cd "C:\...\Replication\Python\Ramp\CF1\20-\p2_cf13"
import pickle
with open("p2_cf13.txt", "rb") as myFile:
    a = pickle.load(myFile)
var1 = list([a[key] for key in ['xi']])
xi= pd.DataFrame(np.concatenate(var1, axis=1), columns=['xi'])
var2 = list([a[key] for key in ['omega']])
omega = pd.DataFrame(np.concatenate(var2, axis=1), columns=['omega'])


integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed' : 0})

simulation = pyblp.Simulation(
    product_formulations=(
        pyblp.Formulation('0 + prices'),
        pyblp.Formulation('0  + loadf'),
        pyblp.Formulation('0 + fcost + fcoa + rampc') 
    ),
    beta=[-0.144502917148697], #stats15 estimated value
    sigma=[8.521796650887],
    gamma=[0.695001758633548, 1.84430434386557, 0.00837604810476922],
    product_data = product_data,
    integration = integration,
    omega = omega,
    xi = xi
)
simulation

cf1_results = simulation.replace_endogenous()
cf1_results

problem = cf1_results.to_problem()
problem

bfgs = pyblp.Optimization('bfgs', {'gtol' : 1e-10})
#bfgs

cf2_results = problem.solve(sigma=0.5 * simulation.sigma,
                        beta = (0.5 * simulation.beta),
                        optimization = bfgs,
                        costs_bounds = (24.999, None))

cf2_results


#Post-estimation results

cd "C:\...\Replication\Python\Ramp\CF2\20-\p2_cf23"
import pickle
a = pyblp.ProblemResults.to_dict(cf2_results)
a.keys()
with open("p2_cf23.txt", "wb") as myFile:
    pickle.dump(a, myFile)
import pickle
with open("p2_cf23.txt", "rb") as myFile:
    p2_cf23 = pickle.load(myFile)

#pvalues
a = p2_cf23
se = list([a[key] for key in ['gamma_se', 'beta_se', 'sigma_se']])
se = np.concatenate(se, axis=0 )

coeff = list([a[key] for key in ['gamma', 'beta', 'sigma']])
coeff = np.concatenate(coeff, axis=0 )
v = list([a[key] for key in ['xi']])
v = np.concatenate(v, axis=0 )
n=len(v)-5 # degrees of freedom n-p
ts= coeff/se

pval = (1-stats.t.cdf(np.abs(ts),n))*2 
interval = stats.norm.interval(0.68, loc=coeff, scale=se/np.sqrt(n))
CImin = interval[0]
CImax = interval[1]


#panda stats
index = ['fcost', 'co2', 'rampc', 'price', 'loadf']

df1 = pd.DataFrame(coeff, index=index, columns=['coeff'])
df2 = pd.DataFrame(se, index=index, columns=['se'])
df3 = pd.DataFrame(pval, index=index, columns=['p-val'])
df4 = pd.DataFrame(CImin, index= index, columns=['CImin'])
df5 = pd.DataFrame(CImax, index= index, columns=['CImax'])

p2_cf23= pd.concat([df1, df2, df3, df4, df5], axis=1)

#additional info
obj = list([a[key] for key in ['objective']])
obj = pd.DataFrame(np.concatenate(obj, axis=0 ), columns=['obj'])

markets = list([a[key] for key in ['contraction_evaluations']])
markets = np.concatenate(markets, axis=0 )
T = pd.Series(len(markets))

add= pd.concat([obj,T], axis=1)

with pd.ExcelWriter('stats24.xlsx') as writer:
    p2_cf23.to_excel(writer, sheet_name = 'p2_cf23', index = True)
    add.to_excel(writer, sheet_name = 'add', index = True)


#build an excel file that contains T market, prices, costs, shares, CS and PS
n2 = len(product_data)
stamp = pd.DataFrame(product_data, columns=['market_ids', 'block', 'hour', 'year', 'plant', 'prices', 'shares', 'fcost', 'fcoa', 'rampc'])
stamp.index = range(n2)
pricescf2 = cf2_results.compute_prices()
sharescf2 = cf2_results.compute_shares()
costscf2 = cf2_results.compute_costs()
markupscf2 = cf2_results.compute_markups(prices=pricescf2, costs=costscf2) #or here it is faster to use the previous calculation
profitscf2 = cf2_results.compute_profits(prices=pricescf2, shares=sharescf2, costs=costscf2)
pcf2= pd.DataFrame(pricescf2, columns=['pricescf2'])
shcf2= pd.DataFrame(sharescf2, columns=['sharescf2'])
cscf2 = cf2_results.compute_consumer_surpluses(prices=pricescf2) 
c= pd.DataFrame(costscf2, columns=['costscf2'])
cc = list([a[key] for key in ['clipped_costs']])
cc = pd.DataFrame(np.concatenate(cc, axis=0 ),columns=['clippedccf2'] )
d= pd.DataFrame(markupscf2, columns=['mkscf2'])
profitss=pd.DataFrame(profitscf2, columns=['pscf2'])
consumers=pd.DataFrame(cscf2, columns=['cscf2']) 

#merging
stampt = stamp[0:len(markets)]
merge = pd.concat([stamp, c,cc, d , profitss], axis=1)
merge2 = pd.concat([stampt, consumers], axis=1)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\p2_cf23\stats24.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
merge.to_excel(writer, sheet_name = 'one', index = True)
merge2.to_excel(writer, sheet_name = 'two', index = True)
writer.save()
writer.close()

#curvature
elasticities = cf2_results.compute_elasticities() 

aggregates = cf2_results.compute_aggregate_elasticities(factor=0.1)
aggregates2 = cf2_results.compute_aggregate_elasticities(factor=0.2)
aggregates3 = cf2_results.compute_aggregate_elasticities(factor=0.3)
aggregates4 = cf2_results.compute_aggregate_elasticities(factor=0.4)
aggregates5 = cf2_results.compute_aggregate_elasticities(factor=0.5)
aggregates6 = cf2_results.compute_aggregate_elasticities(factor=0.6)
aggregates7 = cf2_results.compute_aggregate_elasticities(factor=0.7)
aggregates8 = cf2_results.compute_aggregate_elasticities(factor=0.8)

agg = pd.DataFrame(aggregates,columns=['agg0.1'] )
agg2 = pd.DataFrame(aggregates2,columns=['agg0.2'] )
agg3 = pd.DataFrame(aggregates3,columns=['agg0.3'] )
agg4 = pd.DataFrame(aggregates4,columns=['agg0.4'] )
agg5 = pd.DataFrame(aggregates5,columns=['agg0.5'] )
agg6 = pd.DataFrame(aggregates6,columns=['agg0.6'] )
agg7 = pd.DataFrame(aggregates7,columns=['agg0.7'] )
agg8 = pd.DataFrame(aggregates8,columns=['agg0.8'] )

curvature = pd.concat([agg,agg2,agg3,agg4,agg5,agg6,agg7,agg8 ], axis=1, sort=False)

path = r"C:\...\Replication\Python\Ramp\CF2\20-\p2_cf23\stats24.xlsx"
book = load_workbook(path)
writer = pd.ExcelWriter(path, engine = 'openpyxl')
writer.book = book
curvature.to_excel(writer, sheet_name = 'curv', index = True)
writer.save()

#additional data
diversions = cf2_results.compute_diversion_ratios()
means = cf2_results.extract_diagonal_means(elasticities)
e=pd.DataFrame(elasticities)
di=pd.DataFrame(diversions) 
ie1_o = pd.concat([e, di], axis=1, sort=False)
ie1_o.to_csv('i_1.csv', index = False)
